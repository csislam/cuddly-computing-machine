{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "h89DmUFLFq0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebe6c18c-3709-4e99-de10-8e14b4232ab1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5jyCZJTFtk6"
      },
      "source": [
        "#!ls \"/content/gdrive/MyDrive/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zrcxr5YZKhF",
        "outputId": "87c36563-363f-4cbd-acbb-c3739eabc29e"
      },
      "source": [
        "!git clone https://github.com/knamdar/data.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'data'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 16 (delta 2), reused 16 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (16/16), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RCmKuVNy9Dz",
        "outputId": "ccf5fe3c-fd51-4c2d-a668-7d80d924aa3e"
      },
      "source": [
        "!pip install foolbox"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting foolbox\n",
            "  Downloading foolbox-3.3.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.7/dist-packages (from foolbox) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from foolbox) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from foolbox) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from foolbox) (57.4.0)\n",
            "Collecting requests>=2.24.0\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting GitPython>=3.0.7\n",
            "  Downloading GitPython-3.1.26-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 54.6 MB/s \n",
            "\u001b[?25hCollecting eagerpy==0.29.0\n",
            "  Downloading eagerpy-0.29.0-py3-none-any.whl (30 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2.0.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (1.24.3)\n",
            "Installing collected packages: smmap, gitdb, requests, GitPython, eagerpy, foolbox\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed GitPython-3.1.26 eagerpy-0.29.0 foolbox-3.3.1 gitdb-4.0.9 requests-2.27.1 smmap-5.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90DONPc-ZCLs"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import foolbox as fb\n",
        "from foolbox import PyTorchModel, accuracy, samples\n",
        "from foolbox.attacks import LinfPGD,LinfBasicIterativeAttack,LinfFastGradientAttack,L2CarliniWagnerAttack,LinfDeepFoolAttack,L2DeepFoolAttack,L2BasicIterativeAttack,L2ProjectedGradientDescentAttack\n",
        "\n",
        "class Model_Drop(nn.Module):\n",
        "    def __init__(self):\n",
        "\n",
        "        super(Model_Drop, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3,padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3,padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3,padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3,padding=1)\n",
        "        self.fc1 = nn.Linear(7*7*64, 200)\n",
        "        self.fc2 = nn.Linear(200, 200)\n",
        "        self.fc3 = nn.Linear(200, 10)\n",
        "        self.drop_layer = nn.Dropout(p=0.50)\n",
        "\n",
        "    def last_hidden_layer_output(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.max_pool2d(F.relu(self.conv4(x)), 2)\n",
        "        x = x.view(-1, 7*7*64)\n",
        "        x = self.drop_layer((F.relu(self.fc1(x))))\n",
        "        x = self.drop_layer((F.relu(self.fc2(x))))\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.last_hidden_layer_output(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "mnist_train = datasets.MNIST(\"data\", train=True, download=True, transform=transforms.ToTensor())\n",
        "mnist_test = datasets.MNIST(\"data\", train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = DataLoader(mnist_train, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=128, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.shape[0], -1)\n",
        "\n",
        "torch.manual_seed(2)\n",
        "torch.cuda.manual_seed(2)\n",
        "\n",
        "softmax = nn.Softmax(dim=1)\n",
        "\n",
        "def enable_dropout(model):\n",
        "    \"\"\" Function to enable the dropout layers during test-time \"\"\"\n",
        "    for m in model.modules():\n",
        "        if m.__class__.__name__.startswith('Dropout'):\n",
        "            m.train()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "T = 20\n",
        "\n",
        "def epoch(loader, model, opt=None):\n",
        "\n",
        "    if opt:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    total_loss, total_err = 0., 0.\n",
        "\n",
        "    for X, y in loader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        outputs = model(X)\n",
        "\n",
        "        log_prob_s = F.log_softmax(outputs / T, dim=1)\n",
        "\n",
        "        loss = F.nll_loss(log_prob_s,y)\n",
        "        #loss = criterion(log_prob_s, y)\n",
        "\n",
        "        if opt:\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "        total_err += (outputs.max(dim=1)[1] != y).sum().item()\n",
        "        total_loss += loss.item() * X.shape[0]\n",
        "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-H24ZCH2J-M",
        "outputId": "fdc5a43a-c1ec-4d4a-d486-ba7637597ca8"
      },
      "source": [
        "model_cnn = Model_Drop()\n",
        "model_cnn.to(device)\n",
        "\n",
        "opt = optim.Adam(model_cnn.parameters(), lr=0.001)\n",
        "#opt = optim.SGD(model_cnn.parameters(), lr=0.1, momentum=0.5)\n",
        "\n",
        "for te in range(20):\n",
        "\n",
        "    train_err, train_loss = epoch(train_loader, model_cnn, opt)\n",
        "    test_err, test_loss = epoch(test_loader, model_cnn)\n",
        "\n",
        "    print(*(\"{:.6f}\".format(i) for i in (train_err, test_err)), sep=\"\\t\")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.171417\t0.026800\n",
            "0.042967\t0.016400\n",
            "0.030050\t0.014500\n",
            "0.025000\t0.012400\n",
            "0.020717\t0.011900\n",
            "0.018700\t0.009800\n",
            "0.016683\t0.009000\n",
            "0.014267\t0.008200\n",
            "0.012967\t0.008800\n",
            "0.011700\t0.009100\n",
            "0.010067\t0.007500\n",
            "0.009717\t0.007500\n",
            "0.009717\t0.006600\n",
            "0.008550\t0.007700\n",
            "0.008117\t0.007100\n",
            "0.007650\t0.008400\n",
            "0.006917\t0.006400\n",
            "0.006433\t0.005800\n",
            "0.006000\t0.006600\n",
            "0.006217\t0.007800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXoQsJUH2MZ2",
        "outputId": "7373aa3c-c479-4373-96ca-f3fd54018dd2"
      },
      "source": [
        "model_cnn.eval()\n",
        "torch.save(model_cnn.state_dict(), \"MNIST_DIGIT_model_cnn_teacher_T_20.pt\")\n",
        "\n",
        "model_cnn.load_state_dict(torch.load(\"MNIST_DIGIT_model_cnn_teacher_T_20.pt\"))\n",
        "model_cnn.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model_Drop(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (fc1): Linear(in_features=3136, out_features=200, bias=True)\n",
              "  (fc2): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (fc3): Linear(in_features=200, out_features=10, bias=True)\n",
              "  (drop_layer): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBHgXmWJF1dO"
      },
      "source": [
        "torch.save(model_cnn.state_dict(), \"/content/gdrive/MyDrive/MNIST_DIGIT_model_cnn_teacher_T_20.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}