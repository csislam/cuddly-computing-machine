{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TNjmbw9If9Ge"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.distributions import Categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Model_Drop(nn.Module):\n",
        "    def __init__(self):\n",
        "\n",
        "        super(Model_Drop, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3,padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3,padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3,padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3,padding=1)\n",
        "        self.fc1 = nn.Linear(7*7*64, 200)\n",
        "        self.fc2 = nn.Linear(200, 200)\n",
        "        self.fc3 = nn.Linear(200, 10)\n",
        "        self.drop_layer = nn.Dropout(p=0.50)\n",
        "\n",
        "    def last_hidden_layer_output(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.max_pool2d(F.relu(self.conv4(x)), 2)\n",
        "        x = x.view(-1, 7*7*64)\n",
        "        x = self.drop_layer((F.relu(self.fc1(x))))\n",
        "        x = self.drop_layer((F.relu(self.fc2(x))))\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.last_hidden_layer_output(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "U7IZbR-bgGAw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_cnn = Model_Drop()\n",
        "model_cnn = model_cnn.to(device)"
      ],
      "metadata": {
        "id": "2nNeciZDgIhO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n",
        "mnist_train = datasets.MNIST(\"data\", train=True, download=True, transform=transforms.ToTensor())\n",
        "mnist_test = datasets.MNIST(\"data\", train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Sjxy9n9gLRE",
        "outputId": "360e1a05-c25e-426e-f475-50ce5acfcf1a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 123182182.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 117607469.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 55069844.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 1987120.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "learning_rate = 0.002\n",
        "\n",
        "optimizer = optim.Adam(model_cnn.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "8TECxyZ0gPDu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train(model, train_dataloader):\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "    train_running_loss = 0.0\n",
        "    train_running_correct = 0\n",
        "\n",
        "    for data, target in train_dataloader:\n",
        "\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        train_running_loss += loss.item()\n",
        "        _, preds = torch.max(output.data, 1)\n",
        "        train_running_correct += (preds == target).sum().item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    train_loss = train_running_loss / len(train_dataloader.dataset)\n",
        "    train_accuracy = 100. * train_running_correct / len(train_dataloader.dataset)\n",
        "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}')\n",
        "\n",
        "    return train_loss, train_accuracy"
      ],
      "metadata": {
        "id": "YM8PoCUsgSR3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# validation function\n",
        "def test(model, test_dataloader):\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    val_running_correct = 0\n",
        "\n",
        "    for data, target in test_dataloader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        val_running_loss += loss.item()\n",
        "        _, preds = torch.max(output.data, 1)\n",
        "        val_running_correct += (preds == target).sum().item()\n",
        "\n",
        "    val_loss = val_running_loss / len(test_dataloader.dataset)\n",
        "    val_accuracy = 100. * val_running_correct / len(test_dataloader.dataset)\n",
        "\n",
        "    return val_loss, val_accuracy"
      ],
      "metadata": {
        "id": "6mbA77AngUqR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"BEGIN TRAINING\")\n",
        "\n",
        "train_loss , train_accuracy = [], []\n",
        "val_loss , val_accuracy = [], []\n",
        "\n",
        "for epoch in range(15):\n",
        "\n",
        "    train_epoch_loss, train_epoch_accuracy = train(model_cnn, train_loader)\n",
        "    val_epoch_loss, val_epoch_accuracy = test(model_cnn, test_loader)\n",
        "    train_loss.append(train_epoch_loss)\n",
        "    train_accuracy.append(train_epoch_accuracy)\n",
        "    val_loss.append(val_epoch_loss)\n",
        "    val_accuracy.append(val_epoch_accuracy)\n",
        "\n",
        "\n",
        "torch.save(model_cnn.state_dict(), \"model_cnn_mnist_digit.pt\")\n",
        "\n",
        "print(\"done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN5vXSURgXGK",
        "outputId": "77166ded-7ef9-4c87-cfdc-7b7598e31a7b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BEGIN TRAINING\n",
            "Train Loss: 0.0022, Train Acc: 91.20\n",
            "Train Loss: 0.0007, Train Acc: 97.54\n",
            "Train Loss: 0.0005, Train Acc: 98.19\n",
            "Train Loss: 0.0005, Train Acc: 98.39\n",
            "Train Loss: 0.0004, Train Acc: 98.67\n",
            "Train Loss: 0.0003, Train Acc: 98.86\n",
            "Train Loss: 0.0003, Train Acc: 98.95\n",
            "Train Loss: 0.0003, Train Acc: 98.91\n",
            "Train Loss: 0.0003, Train Acc: 99.09\n",
            "Train Loss: 0.0002, Train Acc: 99.14\n",
            "Train Loss: 0.0002, Train Acc: 99.30\n",
            "Train Loss: 0.0002, Train Acc: 99.24\n",
            "Train Loss: 0.0002, Train Acc: 99.28\n",
            "Train Loss: 0.0002, Train Acc: 99.36\n",
            "Train Loss: 0.0002, Train Acc: 99.28\n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "softmax = nn.Softmax(dim=1)\n",
        "\n",
        "def enable_dropout(model):\n",
        "    \"\"\" Function to enable the dropout layers during test-time \"\"\"\n",
        "    for m in model.modules():\n",
        "        if m.__class__.__name__.startswith('Dropout'):\n",
        "            m.train()"
      ],
      "metadata": {
        "id": "P1fQiflFgbZq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def uncertainty_quantification(image,model,T):\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    dropout_predictions = torch.zeros([T,item_count,10])\n",
        "\n",
        "    for i in range(T):\n",
        "\n",
        "        enable_dropout(model)\n",
        "        output = model((image))\n",
        "        output = softmax(output)\n",
        "\n",
        "        dropout_predictions[i] = output\n",
        "\n",
        "    variance = torch.var(dropout_predictions, dim=0)\n",
        "\n",
        "    var = variance.mean(1,True)\n",
        "    var = var.reshape(1,item_count)\n",
        "\n",
        "    return var.detach()"
      ],
      "metadata": {
        "id": "q8QBPfaliTIQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for X,y in test_loader:\n",
        "    X,y = X.to(device), y.to(device)\n",
        "    break\n",
        "\n",
        "attacked_sample = 9\n",
        "\n",
        "for i, (image,label) in enumerate(test_loader):\n",
        "    image, label = image.to(device), label.to(device)\n",
        "\n",
        "    if i == 0:\n",
        "\n",
        "        sample_img = image[attacked_sample]\n",
        "        sample_img = torch.unsqueeze(sample_img,0)\n",
        "        sample_label = label[attacked_sample]\n",
        "        sample_label = torch.unsqueeze(sample_label, 0)\n",
        "        break\n",
        "\n",
        "with torch.no_grad():\n",
        "    o = model_cnn(sample_img)\n",
        "    o = softmax(o)\n",
        "\n",
        "prediction = o.data.max(1, keepdim=True)[1]\n",
        "print(\"label is \", sample_label)\n",
        "print(\"prediction is \", prediction )\n",
        "\n",
        "print(\"quantified uncertainty is \", uncertainty_quantification(sample_img,model_cnn,50))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PCiC5MbggTh",
        "outputId": "4eee42de-8c05-427e-9bf7-60e7e2d86814"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label is  tensor([9], device='cuda:0')\n",
            "prediction is  tensor([[9]], device='cuda:0')\n",
            "quantified uncertainty is  tensor([[2.0602e-08]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install foolbox\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXb76kuIkRBP",
        "outputId": "1e2939d4-88bf-48ed-d079-2755e3bb13c1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting foolbox\n",
            "  Downloading foolbox-3.3.4-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from foolbox) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from foolbox) (1.11.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from foolbox) (67.7.2)\n",
            "Collecting eagerpy>=0.30.0 (from foolbox)\n",
            "  Downloading eagerpy-0.30.0-py3-none-any.whl (31 kB)\n",
            "Collecting GitPython>=3.0.7 (from foolbox)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.10/dist-packages (from foolbox) (4.10.0)\n",
            "Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from foolbox) (2.31.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython>=3.0.7->foolbox)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->foolbox) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->foolbox) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->foolbox) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->foolbox) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython>=3.0.7->foolbox)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, eagerpy, gitdb, GitPython, foolbox\n",
            "Successfully installed GitPython-3.1.43 eagerpy-0.30.0 foolbox-3.3.4 gitdb-4.0.11 smmap-5.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import foolbox as fb\n",
        "from foolbox import PyTorchModel, accuracy, samples\n",
        "from foolbox.attacks import LinfPGD,LinfBasicIterativeAttack,LinfFastGradientAttack,L2CarliniWagnerAttack,LinfDeepFoolAttack,L2DeepFoolAttack\n",
        "\n",
        "eps = 0.18"
      ],
      "metadata": {
        "id": "u_7fB1Kkgi1q"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack = LinfDeepFoolAttack()\n",
        "fmodel = PyTorchModel(model_cnn, bounds=(0, 1))\n",
        "raw_advs, clipped_advs, success = attack(fmodel, sample_img, sample_label, epsilons=[eps])\n",
        "pert = torch.tensor(clipped_advs[0])\n",
        "\n",
        "with torch.no_grad():\n",
        "    o = model_cnn(pert)\n",
        "    o = softmax(o)\n",
        "\n",
        "prediction = o.data.max(1, keepdim=True)[1]\n",
        "print(\"label is \", sample_label)\n",
        "print(\"prediction is \", prediction )\n",
        "\n",
        "print(\"quantified uncertainty is \", uncertainty_quantification(pert,model_cnn,50))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2R3jggK3g5lA",
        "outputId": "fbfc9cce-de17-4cf1-e385-de25181958aa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label is  tensor([9], device='cuda:0')\n",
            "prediction is  tensor([[7]], device='cuda:0')\n",
            "quantified uncertainty is  tensor([[0.0225]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-97f99ae1a6a2>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  pert = torch.tensor(clipped_advs[0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack = LinfBasicIterativeAttack()\n",
        "fmodel = PyTorchModel(model_cnn, bounds=(0, 1))\n",
        "raw_advs, clipped_advs, success = attack(fmodel, sample_img, sample_label, epsilons=[eps])\n",
        "pert = torch.tensor(clipped_advs[0])\n",
        "\n",
        "with torch.no_grad():\n",
        "    o = model_cnn(pert)\n",
        "    o = softmax(o)\n",
        "\n",
        "prediction = o.data.max(1, keepdim=True)[1]\n",
        "print(\"label is \", sample_label)\n",
        "print(\"prediction is \", prediction )\n",
        "\n",
        "print(\"quantified uncertainty is \", uncertainty_quantification(pert,model_cnn,50))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utP-jYzoh0uk",
        "outputId": "0bc83990-461d-460e-f028-3095f629e674"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label is  tensor([9], device='cuda:0')\n",
            "prediction is  tensor([[4]], device='cuda:0')\n",
            "quantified uncertainty is  tensor([[3.8488e-07]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-8677900afcf0>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  pert = torch.tensor(clipped_advs[0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_uncertainties(model, image, T=50):\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    image = image.to(device)\n",
        "\n",
        "    image = image.detach()\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    dropout_predictions = torch.zeros([T, item_count, 10])\n",
        "\n",
        "    for t in range(T):\n",
        "\n",
        "        enable_dropout(model)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(image)\n",
        "\n",
        "        output_prob = F.softmax(output, dim=1) #shape is 1x10 if item_count is 1 (only one image in input batch)\n",
        "        dropout_predictions[t] = output_prob\n",
        "\n",
        "    mean = torch.mean(dropout_predictions, dim=0)\n",
        "\n",
        "    entropy = Categorical(probs=mean).entropy()\n",
        "\n",
        "    pred_mean = mean\n",
        "\n",
        "    aleatoric = torch.zeros([item_count,10,10])\n",
        "    epistemic = torch.zeros([item_count,10,10])\n",
        "\n",
        "    for t in range(T):\n",
        "\n",
        "        pred_t = dropout_predictions[t]\n",
        "\n",
        "        aleatoric += torch.diag_embed(pred_t, offset=0, dim1=-2, dim2=-1) - pred_t[:, :, None] @ pred_t[:, None, :]\n",
        "        epistemic += (pred_t - pred_mean)[:, :, None] @ (pred_t - pred_mean)[:, None, :]\n",
        "\n",
        "    aleatoric = aleatoric / T #both of them are of shape item_count x 10x10\n",
        "    epistemic = epistemic / T #both of them are of shape item_count x 10x10\n",
        "\n",
        "    aleatoric = torch.diagonal(aleatoric, 0, dim1=-2, dim2=-1)\n",
        "    epistemic = torch.diagonal(epistemic, 0, dim1=-2, dim2=-1)\n",
        "\n",
        "    aleatoric = torch.mean(aleatoric,1,True)\n",
        "    epistemic = torch.mean(epistemic, 1, True)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    return aleatoric.transpose_(0, 1)[0], epistemic.transpose_(0, 1)[0], entropy"
      ],
      "metadata": {
        "id": "Y4wAIc4o-Bj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "33nTOSPFhlhv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}